# DimA

[English](README_EN.md) | ä¸­æ–‡

æœ¬é¡¹ç›®å®ç°äº†DimAï¼ˆç»´åº¦å¢å¼ºï¼ŒDimension Augmentationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œç”¨äºå¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„é«˜æ•ˆé€‚åº”ã€‚é¡¹ç›®è¿˜åŒ…å«äº†ä¸å…¶ä»–ä¸»æµPEFTæ–¹æ³•çš„å…¨é¢å¯¹æ¯”å®éªŒã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

DimAé€šè¿‡åœ¨æ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç½‘ç»œä¸­å¼•å…¥å°‘é‡å¯è®­ç»ƒçš„å¢å¼ºç»´åº¦æ¥å®ç°å‚æ•°é«˜æ•ˆçš„æ¨¡å‹å¾®è°ƒã€‚ç›¸æ¯”ä¼ ç»Ÿçš„å…¨å‚æ•°å¾®è°ƒï¼ŒDimAèƒ½å¤Ÿç”¨æå°‘çš„å‚æ•°å®ç°ç›¸è¿‘ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚

### æ”¯æŒçš„æ–¹æ³•
- **DimA (Augmentation)**: æœ¬é¡¹ç›®æå‡ºçš„æ–°æ–¹æ³•
- **Fine-tuning**: ä¼ ç»Ÿå…¨å‚æ•°å¾®è°ƒ
- **LoRA**: ä½ç§©é€‚åº”æ–¹æ³•
- **Adapter**: é€‚é…å™¨æ–¹æ³•
- **Prompt Tuning**: æç¤ºè°ƒä¼˜
- **Bias Tuning**: åç½®å‚æ•°è°ƒä¼˜

### æ”¯æŒçš„æ¨¡å‹
- **GPT-2** ç³»åˆ— (gpt2, gpt2-medium, gpt2-large)
- **RoBERTa** ç³»åˆ— (roberta-base, roberta-large)

### æ”¯æŒçš„ä»»åŠ¡
- **æ–‡æœ¬ç”Ÿæˆ**: XSumæ‘˜è¦ä»»åŠ¡ (GPT-2)
- **æ–‡æœ¬åˆ†ç±»**: GLUEåŸºå‡†ä»»åŠ¡ (RoBERTa)
  - COLA, QNLI, MRPC, RTE, QQP, MNLI-M, MNLI-MM, SST-2

## ğŸ“ é¡¹ç›®ç»“æ„

```
DimA_full_code/
â”œâ”€â”€ gpt/                    # GPT-2ç›¸å…³å®ç°
â”‚   â”œâ”€â”€ methods/           # å„ç§PEFTæ–¹æ³•å®ç°
â”‚   â”‚   â”œâ”€â”€ modeling_gpt2.py      # é›†æˆDimAçš„GPT-2æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ modeling_gpt2_lora.py # é›†æˆLoRAçš„GPT-2æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ adapter.py             # Adapterå®ç°
â”‚   â”‚   â””â”€â”€ aug.py                 # DimAæ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ train_*.py         # å„ç§æ–¹æ³•çš„è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ utils/             # å·¥å…·å‡½æ•°
â”œâ”€â”€ roberta/                # RoBERTaç›¸å…³å®ç°
â”‚   â”œâ”€â”€ method/            # å„ç§PEFTæ–¹æ³•å®ç°
â”‚   â”œâ”€â”€ train_*.py         # è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ utils/             # å·¥å…·å‡½æ•°
â”œâ”€â”€ metric/                 # è¯„ä¼°æŒ‡æ ‡
â”œâ”€â”€ *.sh                   # è®­ç»ƒå¯åŠ¨è„šæœ¬
â””â”€â”€ save/                  # æ¨¡å‹ä¿å­˜ç›®å½•
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå®‰è£…

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### æ•°æ®ä¸‹è½½

æ•°æ®å’Œé¢„è®­ç»ƒçš„æ£€æŸ¥ç‚¹å¯ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½ï¼š

ğŸ”— **æ•°æ®å’Œæ¨¡å‹ä¸‹è½½**: https://drive.google.com/drive/folders/1fs0qtUeyx1e61aB4Kj7kP6LgOgbZSND8?usp=sharing

ä¸‹è½½å†…å®¹åŒ…æ‹¬ï¼š
- `data.zip`: æ‰€æœ‰å®éªŒæ•°æ®é›†çš„é¢„å¤„ç†ç‰ˆæœ¬
- `save.zip`: é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹

è§£å‹åæ”¾ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š
```bash
# è§£å‹æ•°æ®
unzip data.zip
unzip save.zip
```

### è®­ç»ƒæ¨¡å‹

#### RoBERTaæ¨¡å‹è®­ç»ƒ

```bash
# 1. DimAæ–¹æ³•è®­ç»ƒ
python roberta/train_aug.py --device 0 --seed 1 2 3

# 2. Fine-tuningåŸºçº¿
bash 1_train_ft.sh

# 3. LoRAæ–¹æ³•
bash 2_train_lora.sh

# 4. Adapteræ–¹æ³•
bash 3_train_adapter_few.sh

# 5. Prompt Tuning
bash 8_train_prompt_few.sh

# 6. Bias Tuning
bash 10_train_bt_few.sh
```

#### GPT-2æ¨¡å‹è®­ç»ƒ

```bash
# DimAæ–¹æ³•
python gpt/train_aug.py --device 0

# Fine-tuning
python gpt/train_ft.py

# LoRA
python gpt/train_lora.py --device 0 --type_m lora

# Prompt Tuning
python gpt/train_prompt.py
```

### è¯„ä¼°æ¨¡å‹

```bash
# è¿è¡Œæµ‹è¯•
python test.py
```

## ğŸ”§ é…ç½®è¯´æ˜

### DimAæ ¸å¿ƒå‚æ•°

- `aug_dim`: å¢å¼ºç»´åº¦å¤§å°ï¼Œæ§åˆ¶æ·»åŠ çš„å‚æ•°é‡
- `line_m`: çº¿æ€§å±‚å€æ•°ï¼Œç”¨äºæ§åˆ¶MLPå¢å¼º
- `apply_aug_att`: æ˜¯å¦åœ¨æ³¨æ„åŠ›å±‚åº”ç”¨å¢å¼º
- `apply_aug_mlp`: æ˜¯å¦åœ¨å‰é¦ˆå±‚åº”ç”¨å¢å¼º

### è®­ç»ƒå‚æ•°

- `lr`: å­¦ä¹ ç‡ï¼Œä¸åŒæ–¹æ³•å’Œæ¨¡å‹å¤§å°éœ€è¦è°ƒæ•´
- `epoch`: è®­ç»ƒè½®æ•°
- `bsz`: æ‰¹æ¬¡å¤§å°
- `seed`: éšæœºç§å­ï¼Œç”¨äºç»“æœå¤ç°

## ğŸ“Š å®éªŒç»“æœ

é¡¹ç›®åŒ…å«å®Œæ•´çš„å®éªŒå¯¹æ¯”ï¼Œæ¶µç›–ï¼š

1. **å‚æ•°æ•ˆç‡å¯¹æ¯”**: DimAç›¸æ¯”å…¶ä»–æ–¹æ³•çš„å‚æ•°ä½¿ç”¨é‡
2. **æ€§èƒ½å¯¹æ¯”**: åœ¨å„ä¸ªä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡æ¯”è¾ƒ
3. **æ”¶æ•›æ€§åˆ†æ**: è®­ç»ƒè¿‡ç¨‹çš„æŸå¤±å’ŒæŒ‡æ ‡å˜åŒ–
4. **å°‘æ ·æœ¬å­¦ä¹ **: åœ¨æœ‰é™æ•°æ®ä¸‹çš„è¡¨ç°

ç»“æœä¿å­˜åœ¨`save/`ç›®å½•ä¸‹çš„å¯¹åº”å­æ–‡ä»¶å¤¹ä¸­ã€‚

## ğŸ—‚ï¸ æ–‡ä»¶è¯´æ˜

### è®­ç»ƒè„šæœ¬å‘½åè§„åˆ™

- `*_train_ft.sh`: Fine-tuningè®­ç»ƒ
- `*_train_dima.sh`: DimAæ–¹æ³•è®­ç»ƒ  
- `*_train_lora.sh`: LoRAæ–¹æ³•è®­ç»ƒ
- `*_train_adapter*.sh`: Adapteræ–¹æ³•è®­ç»ƒ
- `*_train_prompt*.sh`: Prompt tuningè®­ç»ƒ
- `*_train_bt*.sh`: Bias tuningè®­ç»ƒ
- `*_few.sh`: å°‘æ ·æœ¬å­¦ä¹ å®éªŒ

### æ ¸å¿ƒæ¨¡å—

- `aug.py`: DimAæ ¸å¿ƒå®ç°ï¼ŒåŒ…å«AugAttã€AugMlpç­‰æ¨¡å—
- `modeling_*.py`: é›†æˆå„ç§PEFTæ–¹æ³•çš„æ¨¡å‹å®ç°
- `dataiter.py`: æ•°æ®è¿­ä»£å™¨
- `recorder.py`: è®­ç»ƒè¿‡ç¨‹è®°å½•

## ğŸ“ˆ å¯è§†åŒ–åˆ†æ

é¡¹ç›®æä¾›å¤šç§å¯è§†åŒ–è„šæœ¬ï¼š

```bash
# ç»˜åˆ¶è®­ç»ƒæ›²çº¿
python plot_train.py

# ç»˜åˆ¶å¯¹æ¯”ç»“æœ
python plot_new.py

# æ§åˆ¶å‘é‡åˆ†æ
python plot_ablation_control_vector.py
```

## ğŸ“ è”ç³»

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤GitHub Issue
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€… 52285901045@stu.ecnu.edu.cn
